{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Development of a software module for recognizing the fingerspelling of the Russian Sign Language based on LSTM](https://www.researchgate.net/publication/355402809_Development_of_a_software_module_for_recognizing_the_fingerspelling_of_the_Russian_Sign_Language_based_on_LSTM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T11:22:32.442742Z",
     "iopub.status.busy": "2024-03-16T11:22:32.442431Z",
     "iopub.status.idle": "2024-03-16T11:22:32.475710Z",
     "shell.execute_reply": "2024-03-16T11:22:32.474927Z",
     "shell.execute_reply.started": "2024-03-16T11:22:32.442708Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/kamilla/Desktop/masters_diploma/SOTA_MODELS/hands_SIBI_training-6.csv\"\n",
    "RANDOM_STATE = 1228\n",
    "keras.utils.set_random_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH, header=0)\n",
    "df.drop(0, axis=0, inplace=True) # первая строчка была проверочная, поэтому избавляемся от нее\n",
    "df = df.sort_values(by=[\"class_type\"])\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_type'] = pd.Categorical(df[\"class_type\"])\n",
    "df['class_type'] = df.class_type.cat.codes\n",
    "\n",
    "df.drop(['wristX', 'wristY', 'wristZ'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = df.pop(\"class_type\")\n",
    "X_data = df.copy()\n",
    "y_data = keras.utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_data,\n",
    "                                                    y_data, \n",
    "                                                    test_size= 1 - train_ratio,\n",
    "                                                   shuffle=True,\n",
    "                                                 random_state=RANDOM_STATE)\n",
    "\n",
    "#test_ratio = 0.10\n",
    "#validation_ratio = 0.10\n",
    "\n",
    "#x_val, x_test, y_val, y_test = train_test_split(x_test, \n",
    "#                                                y_test, \n",
    "#                                                test_size=test_ratio/(test_ratio + validation_ratio)) \n",
    "\n",
    "x_train, x_val = np.array(x_train), np.array(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape {x_train.shape}. y_train shape {y_train.shape}\")\n",
    "#print(f\"X_test shape {x_test.shape}. y_test shape {y_test_cat.shape}\")\n",
    "print(f\"X_val shape {x_val.shape}. y_val shape {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout, Dense\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Conv1D(15, 4, activation='relu', input_shape=(60,1)))\n",
    "model_1.add(MaxPooling1D(pool_size=2))\n",
    "model_1.add(Conv1D(30, 1,  activation='relu', padding=\"same\", use_bias=True))\n",
    "model_1.add(MaxPooling1D(pool_size=2))\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(25, activation='softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T11:23:49.918505Z",
     "iopub.status.busy": "2024-03-16T11:23:49.918140Z",
     "iopub.status.idle": "2024-03-16T11:23:49.926642Z",
     "shell.execute_reply": "2024-03-16T11:23:49.925803Z",
     "shell.execute_reply.started": "2024-03-16T11:23:49.918476Z"
    }
   },
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-16T11:23:51.329760Z",
     "iopub.status.busy": "2024-03-16T11:23:51.329302Z",
     "iopub.status.idle": "2024-03-16T11:30:19.352661Z",
     "shell.execute_reply": "2024-03-16T11:30:19.350355Z",
     "shell.execute_reply.started": "2024-03-16T11:23:51.329722Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model_1.fit(\n",
    "    x=x_train,\n",
    "    y=y_train, \n",
    "    batch_size=64,\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    "    validation_batch_size=32,\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, 43+1)\n",
    "#print(len(epochs))\n",
    "plt.plot(epochs, loss_values, '-', label='Training loss', color='r')\n",
    "plt.plot(epochs, val_loss_values, '-', label='Validation loss', color='g') \n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.argmax(y_val, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model_1.predict(x_val)\n",
    "#y_pred_val = model.predict(x_val_prep)\n",
    "\n",
    "y_preds_class_1 = np.argmax(y_pred, axis=1).tolist()\n",
    "#y_preds_class_val = np.argmax(y_pred_val, axis=1).tolist()\n",
    "\n",
    "accuracy_test = accuracy_score(y_val, y_preds_class_1)\n",
    "print(f\"Точность на тесте (без аугументации): {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(classification_report(y_val, y_preds_class_1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_val, y_preds_class_1, average='weighted')\n",
    "recall = recall_score(y_val, y_preds_class_1, average='weighted')\n",
    "f1 = f1_score(y_val, y_preds_class_1, average='weighted')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 23079,
     "sourceId": 29550,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
